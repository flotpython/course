---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
kernelspec:
  display_name: Python 3
  language: python
  name: python3
language_info:
  name: python
  pygments_lexer: ipython3
nbhosting:
  title: "Caract\xE8res accentu\xE9s"
---

# Caract√®res accentu√©s

+++

<div class="licence">
<span>Licence CC BY-NC-ND</span>
<span>Thierry Parmentelat &amp; Arnaud Legout</span>
<span>Inria - UCA</span>
</div>

+++

Ce compl√©ment expose quelques bases concernant les caract√®res accentu√©s, et notamment les pr√©cautions √† prendre pour pouvoir en ins√©rer dans un programme Python. Nous allons voir que cette question, assez scabreuse, d√©passe tr√®s largement le cadre de Python.

+++

## Compl√©ment - niveau basique

+++

##### Un caract√®re n'est pas un octet

+++

Avec Unicode, on a cass√© le mod√®le *un caract√®re* == *un octet*. Aussi en Python 3, lorsqu'il s'agit de manipuler des donn√©es  provenant de diverses sources de donn√©es¬†:

* le type `byte` est appropri√© si vous voulez charger en m√©moire les donn√©es binaires brutes, sous forme d'octets donc¬†;
* le type `str` est appropri√© pour repr√©senter une cha√Æne de caract√®res - qui, √† nouveau ne sont pas forc√©ment des octets¬†;
* on passe de l'un √† l'autre de ces types par des op√©rations d'encodage et d√©codage, comme illustr√© ci-dessous¬†;
* et pour **toutes** les op√©rations d'encodage et d√©codage, il est n√©cessaire de conna√Ætre l'encodage utilis√©.

+++

![les types bytes et str](media/str-bytes.png)

+++

On peut appeler les m√©thodes `encode` et `decode` sans pr√©ciser l'encodage (dans ce cas Python choisit l'encodage par d√©faut sur votre syst√®me). Cela dit, il est de loin pr√©f√©rable d'√™tre explicite et de choisir son encodage. En cas de doute, il est recommand√© de **sp√©cifier explicitement** `utf-8`, qui se g√©n√©ralise au d√©triment d'encodages anciens comme `cp1252` (Windows) et `iso8859-*`, que de laisser le syst√®me h√¥te choisir pour vous.

+++

##### Utilisation des accents et autres c√©dilles

+++

Python 3 supporte Unicode par d√©faut. Vous pouvez donc, maintenant, utiliser sans aucun risque des accents ou des c√©dilles dans vos cha√Ænes de caract√®res. Il faut cependant faire attention √† deux choses¬†:

* Python supporte Unicode, donc tous les caract√®res du monde, mais les ordinateurs n'ont pas forc√©ment les polices de caract√®res n√©cessaires pour afficher ces caract√®res¬†;
* Python permet d'utiliser des caract√®res Unicode pour les noms de variables, mais nous vous recommandons dans toute la mesure du possible d'√©crire votre code en anglais, comme c'est le cas pour la quasi-totalit√© du code que vous serez amen√©s √† utiliser sous forme de biblioth√®ques. Ceci est particuli√®rement important pour les noms de lignes et de colonnes dans un dataset afin de faciliter les transferts entre logiciels, la majorit√© des logiciels n'acceptant pas les accents et c√©dilles dans les noms de variables.

Ainsi, il faut bien distinguer les cha√Ænes de caract√®res qui doivent par nature √™tre adapt√©es au langage des utilisateurs du programme, et le code source qui lui est destin√© aux programmeurs et qui doit donc √©viter d'utiliser autre chose que de l'anglais.

+++

## Compl√©ment - niveau interm√©diaire

+++

### O√π peut-on mettre des accents¬†?

+++

Cela √©tant dit, si vous devez vraiment mettre des accents dans vos sources, voici ce qu'il faut savoir.

+++

#### Noms de variables

+++

* S'il n'√©tait **pas possible en Python 2** d'utiliser un caract√®re accentu√© dans un **nom de variable** (ou d'un identificateur au sens large), cela est √† pr√©sent **permis en Python 3**¬†:

```{code-cell} ipython3
# pas recommand√©, mais autoris√© par le langage
nb_√©l√®ves = 12
```

* On peut m√™me utiliser des symboles, comme par exemple

```{code-cell} ipython3
from math import cos, pi as ùûü
Œ∏ = ùûü / 4
cos(Œ∏)
```

* Je vous recommande toutefois de **ne pas utiliser** cette possibilit√©, si vous n'√™tes pas extr√™mement familier avec les caract√®res Unicode.

+++

* Enfin, pour √™tre exhaustif, sachez que seule une partie des caract√®res Unicode sont autoris√©s dans ce cadre, c'est heureux parce que les caract√®res comme, par exemple, [l'espace non-s√©cable](http://www.fileformat.info/info/unicode/char/a0/index.htm) pourraient, s'ils √©taient autoris√©s, √™tre la cause de milliers d'heures de debugging √† frustration garantie :)

Pour les curieux, vous pouvez en savoir plus [√† cet endroit de la documentation officielle (en anglais)](https://docs.python.org/3/reference/lexical_analysis.html#identifiers).

+++

#### Cha√Ænes de caract√®res

+++

* Vous pouvez naturellement mettre des accents dans les cha√Ænes de caract√®res. Cela dit, les donn√©es manipul√©es par un programme proviennent pour l'essentiel de sources externes, comme une base de donn√©es ou un formulaire Web, et donc le plus souvent pas directement du code source. Les cha√Ænes de caract√®res pr√©sentes dans du vrai code sont bien souvent limit√©es √† des messages de logging, et le plus souvent d'ailleurs en anglais, donc sans accent.

* Lorsque votre programme doit interagir avec les utilisateurs et qu'il doit donc parler leur langue, c'est une bonne pratique de cr√©er un fichier sp√©cifique, que l'on appelle fichier de ressources, qui contient toutes les cha√Ænes de caract√®res sp√©cifiques √† une langue. Ainsi, la traduction de votre programme consistera √† simplement traduire ce fichier de ressources.

+++

```python
message = "on peut mettre un caract√®re accentu√© dans une cha√Æne"
```

+++

#### Commentaires

+++

* Enfin on peut aussi bien s√ªr mettre dans les commentaires n'importe quel caract√®re Unicode, et donc notamment des caract√®res accentu√©s si on choisit malgr√© tout d'√©crire le code en fran√ßais.

+++ {"latex-replace": ["cos(\u0398) \u27a8 \u2200x \u2208 \u222bf(t)dt\u2230", "cos(\u0398), \u2200x \u2208 \u222bf(t)dt"]}

```python
# on peut mettre un caract√®re accentu√© dans un commentaire
# ainsi que cos(Œò) ‚û® ‚àÄx ‚àà ‚à´f(t)dt‚à∞ vous voyez l'id√©e g√©n√©rale
```

+++

### Qu'est-ce qu'un encodage¬†?

+++

Comme vous le savez, la m√©moire - ou le disque - d'un ordinateur ne permet que de stocker des repr√©sentations binaires. Il n'y a donc pas de fa√ßon "naturelle" de repr√©senter un caract√®re comme 'A', un guillemet ou un point-virgule.

On utilise pour cela un encodage, par exemple [le code `US-ASCII`](http://www.asciitable.com/) stipule, pour faire simple, qu'un 'A' est repr√©sent√© par l'octet 65 qui s'√©crit en binaire 01000001. Il se trouve qu'il existe plusieurs encodages, bien s√ªr incompatibles, selon les syst√®mes et les langues. Vous trouverez plus de d√©tails ci-dessous.

Le point important est que pour pouvoir ouvrir un fichier "proprement", il faut bien entendu disposer du **contenu** du fichier, mais il faut aussi conna√Ætre l'**encodage** qui a √©t√© utilis√© pour l'√©crire.

+++

### Pr√©cautions √† prendre pour l'encodage de votre code source

+++

L'encodage ne concerne pas simplement les objets cha√Æne de caract√®res, mais √©galement votre code source. **Python 3** consid√®re que votre code source utilise **par d√©faut l'encodage `UTF-8`**. Nous vous conseillons de conserver cet encodage qui est celui qui vous offrira le plus de flexibilit√©.

+++

Vous pouvez malgr√© tout changer l'encodage **de votre code source** en faisant figurer dans vos fichiers, **en premi√®re ou deuxi√®me ligne**, une d√©claration comme ceci¬†:

```python
# -*- coding: <nom_de_l_encodage> -*-
```

ou plus simplement, comme ceci¬†:

```python
# coding: <nom_de_l_encodage>
```

Notons que la premi√®re option est √©galement interpr√©t√©e par l'√©diteur de texte _Emacs_ pour utiliser le m√™me encodage. En dehors de l'utilisation d'Emacs, la deuxi√®me option, plus simple et donc plus pythonique, est √† pr√©f√©rer.

+++

Le nom **`UTF-8`** fait r√©f√©rence √† **Unicode** (ou pour √™tre pr√©cis, √† l'encodage le plus r√©pandu parmi ceux qui sont d√©finis dans la norme Unicode, comme nous le verrons plus bas). Sur certains syst√®mes plus anciens vous pourrez √™tre amen√©s √† utiliser un autre encodage. Pour d√©terminer la valeur √† utiliser dans votre cas pr√©cis vous pouvez faire dans l'interpr√©teur interactif¬†:

+++

```python
# ceci doit √™tre ex√©cut√© sur votre machine
import sys
print(sys.getdefaultencoding())
```

+++

Par exemple avec d'anciennes versions de Windows (en principe de plus en plus rares) vous pouvez √™tre amen√©s √† √©crire¬†:

+++

```python
# coding: cp1252
```

+++

La syntaxe de la ligne `coding` est pr√©cis√©e dans [cette documentation](https://docs.python.org/3/reference/lexical_analysis.html#encoding-declarations) et dans le [PEP 263](https://www.python.org/dev/peps/pep-0263/).

+++

### Le grand malentendu

+++ {"latex-replace": [["\u00a4", "\\includegraphics{media/currency-sign.png}"], ["\u20ac", "\\euro"]]}

Si je vous envoie un fichier contenant du fran√ßais encod√© avec, disons, [ISO/IEC 8859-15 - a.k.a. `Latin-9`](http://en.wikipedia.org/wiki/ISO/IEC_8859-15); vous pouvez voir dans la table qu'un caract√®re '‚Ç¨' va √™tre mat√©rialis√© dans mon fichier par un octet '0xA4', soit 164.

Imaginez maintenant que vous essayez d'ouvrir ce m√™me fichier depuis un vieil ordinateur Windows configur√© pour le fran√ßais. Si on ne lui donne aucune indication sur l'encodage, le programme qui va lire ce fichier sur Windows va utiliser l'encodage par d√©faut du syst√®me, c'est-√†-dire [CP1252](http://en.wikipedia.org/wiki/Windows-1252). Comme vous le voyez dans cette table, l'octet '0xA4' correspond au caract√®re ¬§ et c'est √ßa que vous allez voir √† la place de ‚Ç¨.

Contrairement √† ce qu'on pourrait esp√©rer, ce type de probl√®me ne peut pas se r√©gler en ajoutant une balise `# coding: <nom_de_l_encodage>`, qui n'agit que sur l'encodage utilis√© *pour lire le fichier source en question* (celui qui contient la balise).

Pour r√©gler correctement ce type de probl√®me, il vous faut pr√©ciser explicitement l'encodage √† utiliser pour d√©coder le fichier. Et donc avoir un moyen fiable de d√©terminer cet encodage; ce qui n'est pas toujours ais√© d'ailleurs, mais c'est une autre discussion malheureusement.
Ce qui signifie que pour √™tre totalement propre, il faut pouvoir pr√©ciser explicitement le param√®tre `encoding` √† l'appel de toutes les m√©thodes qui sont susceptibles d'en avoir besoin.

+++

### Pourquoi √ßa marche en local¬†?

+++

Lorsque le producteur (le programme qui √©crit le fichier) et le consommateur (le programme qui le lit) tournent dans le m√™me ordinateur, tout fonctionne bien - en g√©n√©ral - parce que les deux programmes se ram√®nent √† l'encodage d√©fini comme l'encodage par d√©faut. 

Il y a toutefois une limite, si vous utilisez un Linux configur√© de mani√®re minimale, il se peut qu'il utilise par d√©faut l'encodage `US-ASCII` - voir plus bas - qui √©tant tr√®s ancien ne "conna√Æt" pas un simple √©, ni a fortiori ‚Ç¨. Pour √©crire du fran√ßais, il faut donc au minimum que l'encodage par d√©faut de votre ordinateur contienne les caract√®res fran√ßais, comme par exemple¬†:

* `ISO 8859-1` (`Latin-1`)
* `ISO 8859-15` (`Latin-9`)
* `UTF-8`
* `CP1252`

√Ä nouveau dans cette liste, il faut clairement pr√©f√©rer UTF-8 lorsque c'est possible.

+++

### Un peu d'histoire sur les encodages

+++

##### Le code `US-ASCII`

+++

Jusque dans les ann√©es 1980, les ordinateurs ne parlaient pour l'essentiel que l'anglais. La premi√®re vague de standardisation avait cr√©√© l'encodage dit `ASCII`, ou encore `US-ASCII` [voir par exemple ici](http://www.asciitable.com), ou encore [en version longue ici](http://en.wikipedia.org/wiki/ASCII).

Le code `US-ASCII` s'√©tend sur 128 valeurs, soit 7 bits, mais est le plus souvent impl√©ment√© sur un octet pour pr√©server l'alignement, le dernier bit pouvant √™tre utilis√© par exemple pour ajouter un code correcteur d'erreur - ce qui √† l'√©poque des modems n'√©tait pas superflu. Bref, la pratique courante √©tait alors de manipuler une cha√Æne de caract√®res comme un tableau d'octets.

+++

##### Les encodages `ISO8859-*` (`Latin*`)

+++

Dans les ann√©es 1990, pour satisfaire les besoins des pays europ√©ens, ont √©t√© d√©finis plusieurs encodages alternatifs, connus sous le nom de [`ISO/IEC 8859-*`](http://en.wikipedia.org/wiki/ISO/IEC_8859), nomm√©s aussi `Latin-*`. Id√©alement, on aurait pu et **certainement d√ª** d√©finir un seul encodage pour repr√©senter tous les nouveaux caract√®res, mais entre toutes les langues europ√©ennes, le nombre de caract√®res √† ajouter √©tait substantiel, et cet encodage unifi√© aurait largement d√©pass√© 256 caract√®res diff√©rents, il n'aurait donc **pas √©t√© possible** de tout faire tenir sur un octet.

On a pr√©f√©r√© pr√©server la "bonne propri√©t√©" du mod√®le *un caract√®re* == *un octet*, ceci afin de pr√©server le code existant qui aurait sinon d√ª √™tre retouch√© ou r√©√©crit.

D√®s lors il n'y avait pas d'autre choix que de d√©finir **plusieurs** encodages distincts, par exemple, pour le fran√ßais on a utilis√© √† l'√©poque [`ISO/IEC 8859-1` (`Latin-1`)](http://en.wikipedia.org/wiki/ISO/IEC_8859-1), pour le russe [`ISO/IEC 5589-5` (`Latin/Cyrillic`)](http://en.wikipedia.org/wiki/ISO/IEC_8859-5).

√Ä ce stade, le ver √©tait dans le fruit. Depuis cette √©poque pour ouvrir un fichier il faut conna√Ætre son encodage.

+++

##### Unicode

+++

Lorsque l'on a ensuite cherch√© √† manipuler aussi les langues asiatiques, il a de toute fa√ßon fallu d√©finir de nouveaux encodages beaucoup plus larges. C'est ce qui a √©t√© fait par le standard [Unicode](http://en.wikipedia.org/wiki/Unicode) qui d√©finit 3 nouveaux encodages¬†:

* [`UTF-8`](http://en.wikipedia.org/wiki/UTF-8) : un encodage √† taille variable, √† base d'octets, qui maximise la compatibilit√© avec US-ASCII¬†;
* [`UTF-16`](http://en.wikipedia.org/wiki/UTF-16) : un encodage √† taille variable, √† base de mots de 16 bits¬†;
* [`UTF-32`](http://en.wikipedia.org/wiki/UTF-32) : un encodage √† taille fixe, √† base de mots de 32 bits¬†;

Ces 3 standards couvrent le m√™me jeu de caract√®res (113 021 tout de m√™me dans la derni√®re version). Parmi ceux-ci le plus utilis√© est certainement `UTF-8`. Un texte ne contenant que des caract√®res du code `US-ASCII` initial peut √™tre lu avec l'encodage `UTF-8`.

Pour √™tre enfin tout √† fait exhaustif, si on sait qu'un fichier est au format Unicode, on peut d√©terminer quel est l'encodage qu'il utilise, en se basant sur les 4 premiers octets du document. Ainsi dans ce cas particulier (lorsqu'on est s√ªr qu'un document utilise un des trois encodages Unicode) il n'est plus n√©cessaire de conna√Ætre son encodage de mani√®re "externe".
